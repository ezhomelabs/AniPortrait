{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/AniPortrait/pretrained_model\n",
    "\n",
    "!apt install espeak-ng aria2 -y\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/audio2pose.pt -d /tmp/AniPortrait/pretrained_model -o audio2pose.pt\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/film_net_fp16.pt  -d /tmp/AniPortrait/pretrained_model -o film_net_fp16.pt \n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/audio2mesh.pt -d /tmp/AniPortrait/pretrained_model -o audio2mesh.pt\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/denoising_unet.pth -d /tmp/AniPortrait/pretrained_model -o denoising_unet.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/motion_module.pth -d /tmp/AniPortrait/pretrained_model -o motion_module.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/pose_guider.pth -d /tmp/AniPortrait/pretrained_model -o pose_guider.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/AniPortrait/resolve/main/reference_unet.pth -d /tmp/AniPortrait/pretrained_model -o reference_unet.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/denoising_unet.pth -d /tmp/AniPortrait/pretrained_model -o denoising_unet.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_depth.pth -d /tmp/AniPortrait/pretrained_model -o guidance_encoder_depth.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_dwpose.pth -d /tmp/AniPortrait/pretrained_model -o guidance_encoder_dwpose.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_normal.pth -d /tmp/AniPortrait/pretrained_model -o guidance_encoder_normal.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/guidance_encoder_semantic_map.pth -d /tmp/AniPortrait/pretrained_model -o guidance_encoder_semantic_map.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/motion_module.pth -d /tmp/AniPortrait/pretrained_model -o motion_module.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/champ/reference_unet.pth -d /tmp/AniPortrait/pretrained_model -o reference_unet.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/image_encoder/config.json -d /tmp/AniPortrait/pretrained_model/image_encoder -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/image_encoder/pytorch_model.bin -d /tmp/AniPortrait/pretrained_model/image_encoder -o pytorch_model.bin\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/sd-vae-ft-mse/config.json -d /tmp/AniPortrait/pretrained_model/sd-vae-ft-mse -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/sd-vae-ft-mse/diffusion_pytorch_model.bin -d /tmp/AniPortrait/pretrained_model/sd-vae-ft-mse -o diffusion_pytorch_model.bin\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/feature_extractor/preprocessor_config.json -d /tmp/AniPortrait/pretrained_model/stable-diffusion-v1-5/feature_extractor -o preprocessor_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/model_index.json -d /tmp/AniPortrait/pretrained_model/stable-diffusion-v1-5 -o model_index.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/unet/config.json -d /tmp/AniPortrait/pretrained_model/stable-diffusion-v1-5/unet -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/resolve/main/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin -d /tmp/AniPortrait/pretrained_model/stable-diffusion-v1-5/unet -o diffusion_pytorch_model.bin\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/champ/raw/main/stable-diffusion-v1-5/v1-inference.yaml -d /tmp/AniPortrait/pretrained_model/stable-diffusion-v1-5 -o v1-inference.yaml\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/config.json -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/feature_extractor_config.json -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o feature_extractor_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/preprocessor_config.json -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o preprocessor_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o pytorch_model.bin\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/special_tokens_map.json -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o special_tokens_map.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/tf_model.h5 -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o tf_model.h5\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/tokenizer_config.json -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o tokenizer_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/facebook/wav2vec2-base-960h/raw/main/vocab.json -d /tmp/AniPortrait/pretrained_model/wav2vec2-base-960h -o vocab.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working\n",
    "!git clone https://github.com/Zejun-Yang/AniPortrait.git\n",
    "\n",
    "%cd AniPortrait\n",
    "!ln -s /tmp/AniPortrait/pretrained_model pretrained_model\n",
    "\n",
    "!pip install -q imageio-ffmpeg==0.4.9 ffmpeg-python==0.2.0 av==11.0.0 omegaconf==2.2.3 diffusers==0.24.0 mediapipe==0.10.11 einops==0.4.1 accelerate==0.21.0 xformers==0.0.25 librosa==0.9.2\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m scripts.audio2vid --config ./configs/prompts/animation_audio.yaml -W 512 -H 512 -acc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
